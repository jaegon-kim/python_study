{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaegon-kim/python_study/blob/main/src/ai_essential_250317/house_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C3HNZJH5LuqI",
      "metadata": {
        "id": "C3HNZJH5LuqI"
      },
      "source": [
        "# House Price Prediction\n",
        "- **목표**\n",
        "  - 이 워크샵은 주어진 데이터셋을 이용해 심층신경망 모델을 학습시켜 주택의 최종 판매 가격(SalePrice)을 예측하는 것이 최종 목표입니다.\n",
        "\n",
        "- **데이터셋 정보**\n",
        "  - 데이터셋은 총 79개의 설명 변수와 타겟 변수인 주택 가격(SalePrice)로 구성됩니다.\n",
        "  - 설명 변수는 주택의 다양한 특성(예: 건축 연도, 면적, 위치, 방 개수 등)을 포함합니다.\n",
        "  - 데이터는 판매 가격이 포함된 학습용 데이터인 `X`, `y` 와 판매 가격이 포함되지 않은 평가용 데이터인 `TEST`파일로 나뉘며, 각각 모델 학습 및 평가에 사용됩니다.\n",
        "    - 평가용 데이터 `TEST`의 판매 가격(SalePrice)를 예측 후 리더보드로 제출하여 평가합니다.\n",
        "\n",
        "- **문제 유형**\n",
        "  - 이 워크샵은 회귀 문제로 연속형 변수를 예측하는 것이 목표입니다. 모델의 성능은 `Mean Absolute Error`로 측정됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FerWbWa8ML9S",
      "metadata": {
        "id": "FerWbWa8ML9S"
      },
      "source": [
        "## 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fbebc02c",
      "metadata": {
        "id": "fbebc02c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install JAEN -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b192c23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b192c23",
        "outputId": "2955dcc7-8c48-4a93-d18a-e134802622a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# 그대로 실행하세요.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4144477e",
      "metadata": {
        "id": "4144477e"
      },
      "outputs": [],
      "source": [
        "# 사용자명을 입력하세요. (이름이 아니여도 괜찮습니다.)\n",
        "username = \"김재곤\"\n",
        "assert username, \"username 변수에 값이 설정되지 않았습니다.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "MkvHc266MWva",
      "metadata": {
        "id": "MkvHc266MWva",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# 그대로 실행하세요.\n",
        "from JAEN.competition import Competition\n",
        "comp = Competition(\n",
        "    username=username,\n",
        "    course_name='AI Essential',\n",
        "    course_round='0317(1)',\n",
        "    competition_name='House Price Prediction'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OSiIE4tdPcSV",
      "metadata": {
        "id": "OSiIE4tdPcSV"
      },
      "source": [
        "## 2. 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Cwo9d1i-ON3u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwo9d1i-ON3u",
        "outputId": "33762697-b5ce-400f-9927-63cb6a5190f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1460, 79]), torch.Size([1460, 1]), torch.Size([1459, 79]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from JAEN.datasets import load_house_price\n",
        "X, y, TEST = load_house_price()\n",
        "X.shape, y.shape, TEST.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I_Vc3a22PgBm",
      "metadata": {
        "id": "I_Vc3a22PgBm"
      },
      "source": [
        "## 3. 제출 예시 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "933af893",
      "metadata": {
        "id": "933af893"
      },
      "outputs": [],
      "source": [
        "# TEST의 예측값 대입 (지금은 0으로 채워진 값 대입)\n",
        "#comp.prediction =  torch.zeros(1459)\n",
        "#comp.prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "wvkBKJUbKsW9",
      "metadata": {
        "id": "wvkBKJUbKsW9"
      },
      "outputs": [],
      "source": [
        "# 제출\n",
        "#comp.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4wNCB3ATlBe4",
      "metadata": {
        "id": "4wNCB3ATlBe4"
      },
      "source": [
        "## 4. 심층신경망 모델을 구성하고 학습하여 TEST를 예측해보세요.\n",
        "- TEST의 예측 결과는 `comp.prediction`에 대입해주세요. **torch.tensor** 형태여야합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "KtwmpH1EibaM",
      "metadata": {
        "id": "KtwmpH1EibaM"
      },
      "outputs": [],
      "source": [
        "# DataLoader 생성\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train_loader = DataLoader(TensorDataset(X, y), batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "-37EJXcZibcK",
      "metadata": {
        "id": "-37EJXcZibcK"
      },
      "outputs": [],
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc_2 = nn.Linear(79, 1024)\n",
        "        self.bn_2 = nn.BatchNorm1d(1024)\n",
        "        #self.fc_1 = nn.Linear(79, 512)\n",
        "        self.fc_1 = nn.Linear(1024, 512)\n",
        "        self.bn_1 = nn.BatchNorm1d(512)\n",
        "        #self.fc0 = nn.Linear(79, 256)\n",
        "        self.fc0 = nn.Linear(512, 256)\n",
        "        self.bn0 = nn.BatchNorm1d(256)\n",
        "        #self.fc1 = nn.Linear(79, 128)\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)  # 10%의 드롭아웃 적용\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.bn_2(self.fc_2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn_1(self.fc_1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn0(self.fc0(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = DNN().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a2237784",
      "metadata": {
        "id": "a2237784"
      },
      "outputs": [],
      "source": [
        "# 손실함수 및 옵티마이저 설정\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "VPKYlayzU0Dt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPKYlayzU0Dt",
        "outputId": "057012c7-ce44-47b3-9afd-d18063d7401c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1460, 79])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3e1ded1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e1ded1c",
        "outputId": "90d52cd7-d3fb-4599-fdd2-4cdcc8698305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5000], Loss: 38954196769.391304\n",
            "Save model Epoch 1 Train Loss : 38954196769.391304\n",
            "Save model Epoch 3 Train Loss : 38889518258.08696\n",
            "Save model Epoch 6 Train Loss : 38654172694.26087\n",
            "Save model Epoch 7 Train Loss : 38448391390.608696\n",
            "Save model Epoch 8 Train Loss : 38159624681.73913\n",
            "Save model Epoch 9 Train Loss : 37748695752.347824\n",
            "Save model Epoch 10 Train Loss : 37218469665.391304\n",
            "Save model Epoch 11 Train Loss : 36639747072.0\n",
            "Save model Epoch 12 Train Loss : 36069348040.347824\n",
            "Save model Epoch 13 Train Loss : 35300189762.78261\n",
            "Save model Epoch 14 Train Loss : 34343478850.782608\n",
            "Save model Epoch 15 Train Loss : 33420112228.173912\n",
            "Save model Epoch 16 Train Loss : 32238745822.608696\n",
            "Save model Epoch 17 Train Loss : 31115693545.739132\n",
            "Save model Epoch 18 Train Loss : 29715132416.0\n",
            "Save model Epoch 19 Train Loss : 28258064562.086956\n",
            "Save model Epoch 20 Train Loss : 26877252385.391304\n",
            "Save model Epoch 21 Train Loss : 25571830182.95652\n",
            "Save model Epoch 22 Train Loss : 23937015585.391304\n",
            "Save model Epoch 23 Train Loss : 22276657419.130436\n",
            "Save model Epoch 24 Train Loss : 21035176203.130436\n",
            "Save model Epoch 25 Train Loss : 19135951671.652172\n",
            "Save model Epoch 26 Train Loss : 17569629384.347828\n",
            "Save model Epoch 27 Train Loss : 16088098348.52174\n",
            "Save model Epoch 28 Train Loss : 14705220173.913044\n",
            "Save model Epoch 29 Train Loss : 13292554351.304348\n",
            "Save model Epoch 30 Train Loss : 12002445612.52174\n",
            "Save model Epoch 31 Train Loss : 10700236466.086956\n",
            "Save model Epoch 32 Train Loss : 9556273853.217392\n",
            "Save model Epoch 33 Train Loss : 8610865530.434782\n",
            "Save model Epoch 34 Train Loss : 7576271053.913043\n",
            "Save model Epoch 35 Train Loss : 6834063782.956522\n",
            "Save model Epoch 36 Train Loss : 5991474710.26087\n",
            "Save model Epoch 37 Train Loss : 5400023418.434783\n",
            "Save model Epoch 38 Train Loss : 5043622194.086957\n",
            "Save model Epoch 39 Train Loss : 4329402941.217391\n",
            "Save model Epoch 40 Train Loss : 4004688612.173913\n",
            "Save model Epoch 41 Train Loss : 3576932009.7391305\n",
            "Save model Epoch 42 Train Loss : 3217256386.7826085\n",
            "Save model Epoch 43 Train Loss : 2873197899.130435\n",
            "Save model Epoch 44 Train Loss : 2784805225.7391305\n",
            "Save model Epoch 45 Train Loss : 2582197875.478261\n",
            "Save model Epoch 46 Train Loss : 2367331511.652174\n",
            "Save model Epoch 47 Train Loss : 2191910633.7391305\n",
            "Save model Epoch 48 Train Loss : 2105978137.0434783\n",
            "Save model Epoch 49 Train Loss : 1940155186.0869565\n",
            "Save model Epoch 50 Train Loss : 1853163156.8695652\n",
            "Save model Epoch 51 Train Loss : 1655381971.4782608\n",
            "Save model Epoch 52 Train Loss : 1301848644.8695652\n",
            "Save model Epoch 53 Train Loss : 1086347673.7391305\n",
            "Save model Epoch 56 Train Loss : 1062903622.2608696\n",
            "Save model Epoch 57 Train Loss : 916898183.6521739\n",
            "Save model Epoch 59 Train Loss : 787120311.6521739\n",
            "Save model Epoch 64 Train Loss : 785212793.0434783\n",
            "Save model Epoch 71 Train Loss : 744112346.4347826\n",
            "Save model Epoch 78 Train Loss : 700564376.3478261\n",
            "Save model Epoch 81 Train Loss : 675739487.6521739\n",
            "Save model Epoch 93 Train Loss : 657431170.7826087\n",
            "Save model Epoch 94 Train Loss : 617044734.2608696\n",
            "Save model Epoch 98 Train Loss : 602498181.9130435\n",
            "Epoch [101/5000], Loss: 679196160.3478261\n",
            "Save model Epoch 102 Train Loss : 577937262.9565217\n",
            "Save model Epoch 125 Train Loss : 540113595.4782609\n",
            "Save model Epoch 155 Train Loss : 527546977.04347825\n",
            "Save model Epoch 157 Train Loss : 502321780.5217391\n",
            "Save model Epoch 179 Train Loss : 500885226.7826087\n",
            "Save model Epoch 182 Train Loss : 489351812.17391306\n",
            "Save model Epoch 192 Train Loss : 474104300.17391306\n",
            "Epoch [201/5000], Loss: 681348448.0\n",
            "Save model Epoch 209 Train Loss : 459090468.17391306\n",
            "Save model Epoch 294 Train Loss : 444694755.4782609\n",
            "Epoch [301/5000], Loss: 454007265.04347825\n",
            "Save model Epoch 319 Train Loss : 438666533.5652174\n",
            "Save model Epoch 398 Train Loss : 429391212.17391306\n",
            "Epoch [401/5000], Loss: 484343892.5217391\n",
            "Save model Epoch 403 Train Loss : 411124660.5217391\n",
            "Save model Epoch 422 Train Loss : 408397449.3913044\n",
            "Save model Epoch 475 Train Loss : 399761741.73913044\n",
            "Epoch [501/5000], Loss: 470598706.7826087\n",
            "Save model Epoch 526 Train Loss : 382066067.4782609\n",
            "Epoch [601/5000], Loss: 458340857.73913044\n",
            "Save model Epoch 605 Train Loss : 381471525.9130435\n",
            "Save model Epoch 614 Train Loss : 349506195.82608694\n",
            "Epoch [701/5000], Loss: 401693810.7826087\n",
            "Save model Epoch 776 Train Loss : 346665125.5652174\n",
            "Save model Epoch 798 Train Loss : 341170355.1304348\n",
            "Epoch [801/5000], Loss: 397887646.95652175\n",
            "Save model Epoch 868 Train Loss : 331681404.5217391\n",
            "Epoch [901/5000], Loss: 378208680.0\n",
            "Save model Epoch 981 Train Loss : 322483242.4347826\n",
            "Save model Epoch 992 Train Loss : 316017414.0869565\n",
            "Epoch [1001/5000], Loss: 415758563.1304348\n",
            "Save model Epoch 1049 Train Loss : 299414639.4782609\n",
            "Save model Epoch 1058 Train Loss : 282680997.04347825\n",
            "Epoch [1101/5000], Loss: 332090910.6086956\n",
            "Epoch [1201/5000], Loss: 349682969.73913044\n",
            "Save model Epoch 1248 Train Loss : 265495347.13043478\n",
            "Epoch [1301/5000], Loss: 313262326.0869565\n",
            "Epoch [1401/5000], Loss: 302340547.1304348\n",
            "Early stopping at epoch 1448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 모델 학습 과정 구현\n",
        "\n",
        "best_loss = float('inf')\n",
        "patience = 200\n",
        "counter = 0\n",
        "\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_loss}')\n",
        "\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        counter = 0\n",
        "        print(f'Save model Epoch {epoch+1} Train Loss : {train_loss}')\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f'Early stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test1) 512/4FC, 2000 epoch Save model Epoch 1893 Train Loss : 238649820.6956522 (Score: 15933)"
      ],
      "metadata": {
        "id": "g-VgNImbJpne"
      },
      "id": "g-VgNImbJpne"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c1439106",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1439106",
        "outputId": "2630c657-2537-40e1-930c-0989bfe3b726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[125103.2344],\n",
              "        [150595.4219],\n",
              "        [177848.1562],\n",
              "        ...,\n",
              "        [151453.2500],\n",
              "        [128436.9375],\n",
              "        [232564.9219]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 학습된 모델의 TEST 예측\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(TEST)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8fb7b590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fb7b590",
        "outputId": "695a487e-e769-4bd5-f395-54697ee5a292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[125103.2344],\n",
              "        [150595.4219],\n",
              "        [177848.1562],\n",
              "        ...,\n",
              "        [151453.2500],\n",
              "        [128436.9375],\n",
              "        [232564.9219]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# comp.prediction에 TEST 예측 결과 대입\n",
        "comp.prediction = outputs\n",
        "comp.prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ddd1d918",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddd1d918",
        "outputId": "210a1d0b-e112-42f0-8d5d-b5052369b4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[House Price Prediction 평가 결과]\n",
            " AI Essential 0317(1) 과정 김재곤님의 점수는 17038.6875 입니다."
          ]
        }
      ],
      "source": [
        "# 제출\n",
        "comp.submit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}