{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaegon-kim/python_study/blob/main/src/ai_essential_250317/house_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C3HNZJH5LuqI",
      "metadata": {
        "id": "C3HNZJH5LuqI"
      },
      "source": [
        "# House Price Prediction\n",
        "- **목표**\n",
        "  - 이 워크샵은 주어진 데이터셋을 이용해 심층신경망 모델을 학습시켜 주택의 최종 판매 가격(SalePrice)을 예측하는 것이 최종 목표입니다.\n",
        "\n",
        "- **데이터셋 정보**\n",
        "  - 데이터셋은 총 79개의 설명 변수와 타겟 변수인 주택 가격(SalePrice)로 구성됩니다.\n",
        "  - 설명 변수는 주택의 다양한 특성(예: 건축 연도, 면적, 위치, 방 개수 등)을 포함합니다.\n",
        "  - 데이터는 판매 가격이 포함된 학습용 데이터인 `X`, `y` 와 판매 가격이 포함되지 않은 평가용 데이터인 `TEST`파일로 나뉘며, 각각 모델 학습 및 평가에 사용됩니다.\n",
        "    - 평가용 데이터 `TEST`의 판매 가격(SalePrice)를 예측 후 리더보드로 제출하여 평가합니다.\n",
        "\n",
        "- **문제 유형**\n",
        "  - 이 워크샵은 회귀 문제로 연속형 변수를 예측하는 것이 목표입니다. 모델의 성능은 `Mean Absolute Error`로 측정됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FerWbWa8ML9S",
      "metadata": {
        "id": "FerWbWa8ML9S"
      },
      "source": [
        "## 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fbebc02c",
      "metadata": {
        "id": "fbebc02c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install JAEN -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b192c23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b192c23",
        "outputId": "f4e2bf99-3cfc-4835-8b9d-77de528619d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# 그대로 실행하세요.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4144477e",
      "metadata": {
        "id": "4144477e"
      },
      "outputs": [],
      "source": [
        "# 사용자명을 입력하세요. (이름이 아니여도 괜찮습니다.)\n",
        "username = \"김재곤\"\n",
        "assert username, \"username 변수에 값이 설정되지 않았습니다.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "MkvHc266MWva",
      "metadata": {
        "id": "MkvHc266MWva",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# 그대로 실행하세요.\n",
        "from JAEN.competition import Competition\n",
        "comp = Competition(\n",
        "    username=username,\n",
        "    course_name='AI Essential',\n",
        "    course_round='0317(1)',\n",
        "    competition_name='House Price Prediction'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OSiIE4tdPcSV",
      "metadata": {
        "id": "OSiIE4tdPcSV"
      },
      "source": [
        "## 2. 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Cwo9d1i-ON3u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwo9d1i-ON3u",
        "outputId": "8e3ea6ed-d456-43ea-d9a6-1de85ed9493d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1460, 79]), torch.Size([1460, 1]), torch.Size([1459, 79]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from JAEN.datasets import load_house_price\n",
        "X, y, TEST = load_house_price()\n",
        "X.shape, y.shape, TEST.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I_Vc3a22PgBm",
      "metadata": {
        "id": "I_Vc3a22PgBm"
      },
      "source": [
        "## 3. 제출 예시 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "933af893",
      "metadata": {
        "id": "933af893"
      },
      "outputs": [],
      "source": [
        "# TEST의 예측값 대입 (지금은 0으로 채워진 값 대입)\n",
        "#comp.prediction =  torch.zeros(1459)\n",
        "#comp.prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "wvkBKJUbKsW9",
      "metadata": {
        "id": "wvkBKJUbKsW9"
      },
      "outputs": [],
      "source": [
        "# 제출\n",
        "#comp.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4wNCB3ATlBe4",
      "metadata": {
        "id": "4wNCB3ATlBe4"
      },
      "source": [
        "## 4. 심층신경망 모델을 구성하고 학습하여 TEST를 예측해보세요.\n",
        "- TEST의 예측 결과는 `comp.prediction`에 대입해주세요. **torch.tensor** 형태여야합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "KtwmpH1EibaM",
      "metadata": {
        "id": "KtwmpH1EibaM"
      },
      "outputs": [],
      "source": [
        "# DataLoader 생성\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train_loader = DataLoader(TensorDataset(X, y), batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "-37EJXcZibcK",
      "metadata": {
        "id": "-37EJXcZibcK"
      },
      "outputs": [],
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc_2 = nn.Linear(79, 1024)\n",
        "        self.bn_2 = nn.BatchNorm1d(1024)\n",
        "        #self.fc_1 = nn.Linear(79, 512)\n",
        "        self.fc_1 = nn.Linear(1024, 512)\n",
        "        self.bn_1 = nn.BatchNorm1d(512)\n",
        "        #self.fc0 = nn.Linear(79, 256)\n",
        "        self.fc0 = nn.Linear(512, 256)\n",
        "        self.bn0 = nn.BatchNorm1d(256)\n",
        "        #self.fc1 = nn.Linear(79, 128)\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)  # 10%의 드롭아웃 적용\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.bn_2(self.fc_2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn_1(self.fc_1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn0(self.fc0(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = DNN().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a2237784",
      "metadata": {
        "id": "a2237784"
      },
      "outputs": [],
      "source": [
        "# 손실함수 및 옵티마이저 설정\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "VPKYlayzU0Dt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPKYlayzU0Dt",
        "outputId": "753750a7-eae6-4ac6-dded-42110e99dd28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1460, 79])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3e1ded1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e1ded1c",
        "outputId": "53126520-2899-40b5-fe77-04741699e063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2000], Loss: 39053602637.91304\n",
            "Save model Epoch 1 Train Loss : 39053602637.91304\n",
            "Save model Epoch 2 Train Loss : 38961861542.95652\n",
            "Save model Epoch 3 Train Loss : 38889653248.0\n",
            "Save model Epoch 5 Train Loss : 38822968720.695656\n",
            "Save model Epoch 6 Train Loss : 38668283814.95652\n",
            "Save model Epoch 7 Train Loss : 38657404126.608696\n",
            "Save model Epoch 8 Train Loss : 38208915634.08696\n",
            "Save model Epoch 9 Train Loss : 38037950686.608696\n",
            "Save model Epoch 10 Train Loss : 37928717401.04348\n",
            "Save model Epoch 11 Train Loss : 37132563767.652176\n",
            "Save model Epoch 12 Train Loss : 36719069362.08696\n",
            "Save model Epoch 13 Train Loss : 36040608545.391304\n",
            "Save model Epoch 14 Train Loss : 35228721641.73913\n",
            "Save model Epoch 15 Train Loss : 34424601065.73913\n",
            "Save model Epoch 16 Train Loss : 33554468864.0\n",
            "Save model Epoch 17 Train Loss : 32586361455.304348\n",
            "Save model Epoch 18 Train Loss : 31523162646.260868\n",
            "Save model Epoch 19 Train Loss : 30523841803.130436\n",
            "Save model Epoch 20 Train Loss : 29462213186.782608\n",
            "Save model Epoch 21 Train Loss : 27924076143.304348\n",
            "Save model Epoch 22 Train Loss : 26640756825.04348\n",
            "Save model Epoch 23 Train Loss : 25456053069.913044\n",
            "Save model Epoch 24 Train Loss : 23843199198.608696\n",
            "Save model Epoch 25 Train Loss : 22431108118.260868\n",
            "Save model Epoch 26 Train Loss : 21046847309.913044\n",
            "Save model Epoch 27 Train Loss : 19726143465.739132\n",
            "Save model Epoch 28 Train Loss : 18206421793.391304\n",
            "Save model Epoch 29 Train Loss : 16903058231.652174\n",
            "Save model Epoch 30 Train Loss : 15369041497.043478\n",
            "Save model Epoch 31 Train Loss : 14188541451.130434\n",
            "Save model Epoch 32 Train Loss : 13061391760.695652\n",
            "Save model Epoch 33 Train Loss : 11844231702.26087\n",
            "Save model Epoch 34 Train Loss : 10737887287.652174\n",
            "Save model Epoch 35 Train Loss : 9591752069.565218\n",
            "Save model Epoch 36 Train Loss : 8791087104.0\n",
            "Save model Epoch 37 Train Loss : 7981854597.565217\n",
            "Save model Epoch 38 Train Loss : 7119221186.782609\n",
            "Save model Epoch 39 Train Loss : 6555270266.434783\n",
            "Save model Epoch 40 Train Loss : 5868771945.73913\n",
            "Save model Epoch 41 Train Loss : 5145436994.782609\n",
            "Save model Epoch 42 Train Loss : 4743884889.043478\n",
            "Save model Epoch 43 Train Loss : 4323730971.826087\n",
            "Save model Epoch 44 Train Loss : 3972426312.347826\n",
            "Save model Epoch 45 Train Loss : 3547056640.0\n",
            "Save model Epoch 46 Train Loss : 3346292299.130435\n",
            "Save model Epoch 47 Train Loss : 3075680818.0869565\n",
            "Save model Epoch 48 Train Loss : 2928812552.347826\n",
            "Save model Epoch 49 Train Loss : 2715646398.6086955\n",
            "Save model Epoch 50 Train Loss : 2569223741.2173915\n",
            "Save model Epoch 51 Train Loss : 2473960712.347826\n",
            "Save model Epoch 52 Train Loss : 2274972916.869565\n",
            "Save model Epoch 53 Train Loss : 2071541193.7391305\n",
            "Save model Epoch 54 Train Loss : 1932111405.9130435\n",
            "Save model Epoch 56 Train Loss : 1869850991.3043478\n",
            "Save model Epoch 57 Train Loss : 1630086068.8695652\n",
            "Save model Epoch 60 Train Loss : 1540366342.9565217\n",
            "Save model Epoch 62 Train Loss : 1527539801.0434783\n",
            "Save model Epoch 69 Train Loss : 1474382799.3043478\n",
            "Save model Epoch 70 Train Loss : 1274884544.6956522\n",
            "Save model Epoch 72 Train Loss : 1159149758.6086957\n",
            "Save model Epoch 73 Train Loss : 1060864473.0434783\n",
            "Save model Epoch 76 Train Loss : 869409253.5652174\n",
            "Save model Epoch 80 Train Loss : 835572375.6521739\n",
            "Save model Epoch 83 Train Loss : 800765694.9565217\n",
            "Save model Epoch 89 Train Loss : 728206803.826087\n",
            "Save model Epoch 100 Train Loss : 690747859.4782609\n",
            "Epoch [101/2000], Loss: 795957438.6086956\n",
            "Save model Epoch 111 Train Loss : 686725068.5217391\n",
            "Save model Epoch 112 Train Loss : 638290315.1304348\n",
            "Save model Epoch 119 Train Loss : 616739977.0434783\n",
            "Save model Epoch 120 Train Loss : 580293297.3913044\n",
            "Save model Epoch 134 Train Loss : 560724274.4347826\n",
            "Save model Epoch 167 Train Loss : 549191899.826087\n",
            "Save model Epoch 168 Train Loss : 533715600.0\n",
            "Epoch [201/2000], Loss: 606300238.2608696\n",
            "Save model Epoch 202 Train Loss : 529357112.34782606\n",
            "Save model Epoch 220 Train Loss : 453768437.2173913\n",
            "Save model Epoch 224 Train Loss : 435069530.0869565\n",
            "Epoch [301/2000], Loss: 546921616.3478261\n",
            "Save model Epoch 367 Train Loss : 408995962.6086956\n",
            "Epoch [401/2000], Loss: 526746378.4347826\n",
            "Save model Epoch 421 Train Loss : 401054626.0869565\n",
            "Save model Epoch 485 Train Loss : 389279218.4347826\n",
            "Epoch [501/2000], Loss: 472287076.8695652\n",
            "Save model Epoch 580 Train Loss : 368624100.5217391\n",
            "Epoch [601/2000], Loss: 413275209.04347825\n",
            "Epoch [701/2000], Loss: 413100614.6086956\n",
            "Save model Epoch 705 Train Loss : 330575859.82608694\n",
            "Epoch [801/2000], Loss: 477977648.6956522\n",
            "Save model Epoch 897 Train Loss : 320426608.6956522\n",
            "Epoch [901/2000], Loss: 357385475.4782609\n",
            "Save model Epoch 986 Train Loss : 317514354.6086956\n",
            "Epoch [1001/2000], Loss: 425101184.6956522\n",
            "Epoch [1101/2000], Loss: 386514834.7826087\n",
            "Save model Epoch 1184 Train Loss : 303319825.3913044\n",
            "Epoch [1201/2000], Loss: 349068063.65217394\n",
            "Save model Epoch 1237 Train Loss : 289686364.17391306\n",
            "Save model Epoch 1291 Train Loss : 287155976.6956522\n",
            "Epoch [1301/2000], Loss: 312989793.73913044\n",
            "Save model Epoch 1304 Train Loss : 278315994.0869565\n",
            "Epoch [1401/2000], Loss: 331699591.4782609\n",
            "Epoch [1501/2000], Loss: 338724507.82608694\n",
            "Save model Epoch 1518 Train Loss : 274551480.6956522\n",
            "Save model Epoch 1541 Train Loss : 269991822.4347826\n",
            "Save model Epoch 1551 Train Loss : 262340162.7826087\n",
            "Epoch [1601/2000], Loss: 347625769.3913044\n",
            "Save model Epoch 1658 Train Loss : 261412439.47826087\n",
            "Epoch [1701/2000], Loss: 334720596.8695652\n",
            "Save model Epoch 1725 Train Loss : 258524524.52173913\n",
            "Save model Epoch 1771 Train Loss : 252517591.3043478\n",
            "Epoch [1801/2000], Loss: 322595825.3913044\n",
            "Save model Epoch 1883 Train Loss : 250159976.3478261\n",
            "Save model Epoch 1893 Train Loss : 238649820.6956522\n",
            "Epoch [1901/2000], Loss: 294041286.95652175\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# 모델 학습 과정 구현\n",
        "\n",
        "best_loss = float('inf')\n",
        "patience = 1000\n",
        "counter = 0\n",
        "\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_loss}')\n",
        "\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        counter = 0\n",
        "        print(f'Save model Epoch {epoch+1} Train Loss : {train_loss}')\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f'Early stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test1) 512/4FC, 2000 epoch Save model Epoch 1893 Train Loss : 238649820.6956522 (Score: 15933)"
      ],
      "metadata": {
        "id": "g-VgNImbJpne"
      },
      "id": "g-VgNImbJpne"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c1439106",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1439106",
        "outputId": "11c02e0a-6cdb-4a46-bbcb-d5ed58cf85ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[127607.7266],\n",
              "        [155100.5156],\n",
              "        [181143.1719],\n",
              "        ...,\n",
              "        [158094.3281],\n",
              "        [134438.0156],\n",
              "        [228899.9688]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 학습된 모델의 TEST 예측\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(TEST)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8fb7b590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fb7b590",
        "outputId": "1bd16708-95c5-4013-8715-0ffd7c808b16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[127607.7266],\n",
              "        [155100.5156],\n",
              "        [181143.1719],\n",
              "        ...,\n",
              "        [158094.3281],\n",
              "        [134438.0156],\n",
              "        [228899.9688]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# comp.prediction에 TEST 예측 결과 대입\n",
        "comp.prediction = outputs\n",
        "comp.prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ddd1d918",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddd1d918",
        "outputId": "f2ab8cfa-9629-4811-e41c-db48d5137d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[House Price Prediction 평가 결과]\n",
            " AI Essential 0317(1) 과정 김재곤님의 점수는 15933.7216796875 입니다."
          ]
        }
      ],
      "source": [
        "# 제출\n",
        "comp.submit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}